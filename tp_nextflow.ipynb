{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c18a119f-ab4b-4f73-ac3e-7e0ba72cbf6b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Your first pipeline with NextFlow\n",
    "\n",
    "## Nextflow vs Snakemake: the endless debate\n",
    "\n",
    "|             | Snakemake   | Nextflow    |\n",
    "| ----------- | ----------- | ----------- |\n",
    "| Community | Informatic/bioinformatic | Biologist/bioinformatic |\n",
    "| Reusable code | Snakemake wrappers | Nf-core modules |\n",
    "| Rerun a workflow on same data | Option to rerun all, use cache by default | Option to use cache, rerun all by default |\n",
    "| Langage | Python | Groovy but function calling works like in python and R |\n",
    "| Use other workflow manager | Accept nextflow pipeline calling | Work only with himself |\n",
    "| Name of input and output | Need to use wildcards | Function basename deals with it |\n",
    "\n",
    "\n",
    "\n",
    "In both :\n",
    "\n",
    "- You have a strong architecture\n",
    "\n",
    "- You can use conda/docker/singularity and so on\n",
    "\n",
    "- A first principal rule (\"workflow\" nextflow and \"all\" in snakemake)\n",
    "\n",
    "- You have report (timeline, cpus usage, dag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d94a31-f945-4967-82cb-35170feffc3e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**schedule:**\n",
    "- What's a pipeline?\n",
    "\n",
    "- What about NextFlow?\n",
    "\n",
    "- NextFlow script for a 2-steps pipeline\n",
    "\n",
    "- A few more tips & tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647bfb62-1299-44b5-862d-1a25becaabd5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Pre-requisites\n",
    "\n",
    "**1- data:** input data to run the workflow example are reduced RNASeq reads files. Download data from [zenodo here](https://zenodo.org/record/3997237) and unzip (`gunzip FAIR_Bioinfo_data.tar.gz`) on the same repository of the notebook\n",
    "\n",
    "**2- NextFlow:** For this tutorial, we'll use a handy docker image with Jupyter-lab and NextFlow.\n",
    "\n",
    "You can download it here: *Lien !!*\n",
    "And run it with this command: *Commande !!*\n",
    "\n",
    "If you want to use NextFlow outside of a container, we advise you to install it via conda:  \n",
    "`conda create -n nextflow_22.04.0 -c bioconda nextflow=22.04.0 fastqc=0.11.9 multiqc=1.12`  \n",
    "`activate nextflow_22.04.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4455298-a049-4f8b-ad6f-adbe3f956650",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Workflow definition\n",
    "\n",
    "A pool of commands, progressively linked by the treatments, from the input data towards the results:\n",
    "\n",
    "<img src=\"images/FAIR_smk_data_wf.png\" alt=\"a workflow\" width=80%/>\n",
    "\n",
    "_arrow: output of tool n‚àí1 = input for tool n_\n",
    "\n",
    "In case of data paralelization, several data flows can be processed in parallel:\n",
    "\n",
    "<img src=\"images/FAIR_smk_n_data_wf.png\" alt=\"a workflow\" width=80%/>\n",
    "\n",
    "With a multi-cores PC or a computational cluster (ex. 2000 cores), one (or more) core can be attributed to one workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326231e7-0fcd-4cc4-a9d6-3a2e8f3a348a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Workflow management systems\n",
    "\n",
    "Many workflow management systems, many forms:\n",
    "- command line: shell (but doesn‚Äôt handle parallelization alone, need to script it, not easy)\n",
    "- rule: <a href=\"https://snakemake.readthedocs.io/en/stable/\"><img src=\"images/logo-snakemake.png\" alt=\"snakemake\" width=16%/></a>, <a href=\"https://cmake.org\"><img src=\"images/logo-cmake.png\" alt=\"c-make\" width=10%/></a>, <a href=\"https://www.nextflow.io/\"><img src=\"images/logo-nextflow.png\" alt=\"nextflow\" width=10%/></a>, ...\n",
    "- graphic interface: <a href=\"https://usegalaxy.org\"><img src=\"images/logo-galaxy.png\" alt=\"Galaxy\" width=12%/></a>, Taverna, Keppler, ...\n",
    "\n",
    "**pros:** <br>\n",
    "- important for reproducibility (keep track of when each file was generated, and by which operation), <br>\n",
    "- manage parallelization\n",
    "\n",
    "**cons:** <br>\n",
    "- learning effort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22492525-eea3-4c7a-ba3c-c05e967c6f52",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Here, we will talk about <a href=\"https://www.nextflow.io/index.html/\"><img src=\"images/logo-nextflow.png\" alt=\"NextFlow\" width=16%/></a>:\n",
    "- works on files (rather than streams, reading/writing from databases or passing variables in memory)\n",
    "- is based on Python (but know how to code in Python is not required to work with Snakemake)\n",
    "- has features for defining the environment with which each task is carried out (running a large number of small third-party tools is current in bioinformatics)\n",
    "- is easily to be scaled from desktop to server, cluster, grid or cloud environments (ie. develop on laptop using a small subset of data, run the real analysis on a cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c05912d-7ca9-4086-aeba-81dd8b28f845",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Nextflow scripting principles\n",
    "\n",
    "Nextflow uses the groovy language, which aims to be \"Python for Java\". In practice, it is a very minimal language so you don't have to learn a whole new syntax in order to start with nextflow.  \n",
    "\n",
    "First, you will need to define your input `channels`, which could be compared to pipes, that will carry your files through the pipeline to the appropriate `processes`. Then, you will define processes by the `input` they need, the `output` they're expected to produce and the `script` that will perfom the actions to go from one to the other. Once this is done, you need to link all your processes together in a workflow to specify their order and how they relate to each other.  \n",
    "\n",
    "A basic Nextflow script looks like this:  \n",
    "\n",
    "*TODO: un sch√©ma avec des tuyaux et des process*\n",
    "\n",
    "```{nextflow}\n",
    "#! usr/bin/env nextflow\n",
    "\n",
    "nextflow.enable.dsl=2\n",
    "\n",
    "params.input = \"data.txt\"\n",
    "\n",
    "input_chan = Channel.fromPath(params.input)\n",
    "\n",
    "process process_1 {\n",
    "    input:\n",
    "        path input\n",
    "    output:\n",
    "        path output\n",
    "\n",
    "    script:\n",
    "    \"\"\"\n",
    "        $input > $output\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "workflow{\n",
    "    process_1(input_chan)\n",
    "}\n",
    "```\n",
    "\n",
    "The first line is call a shebang, it's used to tell you system to use the nextflow interpreter to execute the script. Then, `nextflow.enable.dsl=2` allows your script to use the DSL2 version of Nextflow (more info [here](https://www.nextflow.io/docs/latest/dsl2.html)).\n",
    "\n",
    "Then, you define an `input` parameter with a default value that can be overridden through the command line. The files given through this parameters are \"poured\" in a canal in the next line.\n",
    "\n",
    "The `process` block defined which files are expected as input and output, and how to process them.\n",
    "\n",
    "The last block of the pipeline defines the workflow itself, using everything that was defined before.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b100e-4ab1-4311-b2ea-81e757af9331",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Let's start scripting!\n",
    "\n",
    "For this tutorial, we will use fastQC on a few light fastq files (process 1), then we will summarize the results using multiQC (process 2).\n",
    "\n",
    "Create a file called `fair_nextflow.nf` and copy/paste the first two lines we saw earlier:\n",
    "\n",
    "```\n",
    "#! usr/bin/env nextflow\n",
    "\n",
    "nextflow.enable.dsl=2\n",
    "```\n",
    "\n",
    "Then, we will need to define our input parameter and input channel. In this case, the input files are the gzipped fastq files we downloaded in the Data directory. Let's add them to the script with the following lines:\n",
    "\n",
    "```\n",
    "params.input = \"Data/*.fastq.gz\"\n",
    "\n",
    "input_fastq = Channel.fromPath(params.input)\n",
    "```\n",
    "\n",
    "Note that we are using a *wildcard* in our input path definition. It behaves a little like a funnel on top of our channel path: the pipeline will take as input every file with the *.fastq.gz* extension in the Data directory.  \n",
    "\n",
    "Now that the inputs are defined, lets create our first process by adding this block to the script:  \n",
    "\n",
    "```\n",
    "process fastqc {\n",
    "    input:\n",
    "        path input_fastq\n",
    "    output:\n",
    "        path \"FastQC/*_fastqc.zip\"\n",
    "        path \"FastQC/*_fastqc.html\"\n",
    "\n",
    "    script:\n",
    "    \"\"\"\n",
    "        fastqc -outdir FastQC/ ${input_fastq}\n",
    "    \"\"\"\n",
    "}\n",
    "```\n",
    "The process we just defined takes an `input` fastq file, runs fastQC on it and saves the results (ain the FastQC/ directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb95bbd-966b-4810-a7d1-99653a41db16",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Generalization with wilcards\n",
    "Snakemake use _wildcards_ allow to replace parts of filename:\n",
    "- reduce hardcoding: more flexible input and output directives, work on new data without modification\n",
    "- are automatically resolved (ie. replaced by regular expression \".+\" in filenames)\n",
    "- are writing into {}\n",
    "- are specific to a rule\n",
    "\n",
    "A same file can be accessed by different matchings:<br>\n",
    "Ex. with the file `101/file.A.txt` :<br>\n",
    "rule one : `output : \"{set}1/file.{grp}.txt\" # => set=10, grp=A`<br>\n",
    "rule two : `output : \"{set}/file.A.{ext}\" # = > set=101, ext=txt`<br>\n",
    "(more on [wildcards](https://snakemake.readthedocs.io/en/stable/snakefiles/rules.html#wildcards) in the snakemake documentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cda3e9f-c631-47ef-ba6e-61e05fd195c7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### With and without wildcards example\n",
    "\n",
    "without wildcards, `uniprot_wow.smk`:\n",
    "```\n",
    "rule get_prot:\n",
    "  output: \"P10415.fasta\", \"P01308.fasta\"\n",
    "  run :\n",
    "    shell(\"wget https://www.uniprot.org/uniprot/P10415.fasta\")\n",
    "    shell(\"wget https://www.uniprot.org/uniprot/P01308.fasta\")\n",
    "```\n",
    "\n",
    "with wildcards, `uniprot_wiw.smk`:\n",
    "```\n",
    "rule all:\n",
    "  input: \"P10415.fasta\", \"P01308.fasta\"\n",
    "\n",
    "rule get_prot:\n",
    "  output: \"{prot}.fasta\"\n",
    "  shell: \"wget https://www.uniprot.org/uniprot/{wildcards.prot}.fasta\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff4afc8-9456-4032-ac20-4ddc6f0bbb7e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Input (output) specifications\n",
    "enumerated:\n",
    "```\n",
    "rule all:\n",
    "  input: \"P10415.fasta\",\"P01308.fasta\"\n",
    "```\n",
    "\n",
    "python list & wildcards:\n",
    "```\n",
    "DATASETS=[\"P10415\",\"P01308\"]\n",
    "rule all:\n",
    "  input: [\"{dataset}.fasta\".format(dataset=dataset) for dataset in DATASETS]\n",
    "```\n",
    "\n",
    "expand() & wildcards:\n",
    "```\n",
    "DATASETS=[\"P10415\",\"P01308\"]\n",
    "rule all:\n",
    "  input: expand(\"{dataset}.fasta\",dataset=DATASETS)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c273c30f-2f58-4cc3-982d-cd959d87cd2d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "##¬†The Snakefile example\n",
    "\n",
    "The final objective is to create a snakefile to manage a small workflow with 2 steps: i) fastqc ii) multiqc \n",
    "\n",
    "<img src=\"images/FAIR_WF_2steps.png\" alt=\"a 2 steps workflow example\" width=40%/>\n",
    "\n",
    "These two tools belonging to the bioinformatics domain allow to check the quality of high throughput sequence data. \n",
    "They are accessible via a Conda environment, `envfair.yml` or already included in the docker image ` test/jupylab_smk:1.0` (see prerequisites, on top).\n",
    "\n",
    "Sequence data stand in the `${PWD}/Data` repository (see prerequisites, on top). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a32a62-c888-4ca1-aef9-754da0ff7910",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**note:** \n",
    "- you will execute several cycles: executing snakefile, observing the result and improving the code. \n",
    "Each code version will be noted `ex1_oX.smk` with _ex_ for example, _o_ for objective, and _X_ a progressive digit.\n",
    "- if you have already run this notebook, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93727674-55fb-4403-b858-022235883f60",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "rm -Rf FastQC multiqc_data multiqc_report.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5ccc98-b347-4551-a6de-90e3a7f1d31a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Objective 1: The rule concept\n",
    "\n",
    "**Objective 1:** Create a snakemake file named `ex1_o1.smk` including the first step of the\n",
    "RNAseq workflow (the reads quality checking thank to the fastqc tool) on one of the RNAseq files\n",
    "\n",
    "**Hint:** \n",
    "- input file: `SRR3099585_chr18.fastq.gz` in the ${PWD}/Data directory<br>\n",
    "- fastqc access: access: through docker or conda environment (see prerequisites on top)<br>\n",
    "- fastqc command: `fastqc --outdir FastQCResultDirectory inputFileName`<br>\n",
    "- the 2 result files (`*_fastqc.zip` & `*_fastqc.html`) will be located in your `outdir` and named based on the prefix of input file (eg. `SRR3099585_chr18_fastqc.zip`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1584099-bea0-47c7-a948-4108c86d3e30",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Objective 1: solution\n",
    "\n",
    "Code for `ex1_o1.smk`:\n",
    "```\n",
    "rule fastqc:\n",
    "  output:\n",
    "    \"FastQC/SRR3099585_chr18_fastqc.zip\", \n",
    "    \"FastQC/SRR3099585_chr18_fastqc.html\"\n",
    "  input:\n",
    "    \"Data/SRR3099585_chr18.fastq.gz\"\n",
    "  shell: \"fastqc --outdir FastQC/ {input}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18f28331-41dd-4a27-854e-e36e6327b6cb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building DAG of jobs...\n",
      "Using shell: /usr/bin/bash\n",
      "Provided cores: 1 (use --cores to define parallelism)\n",
      "Rules claiming more threads will be scaled down.\n",
      "Job stats:\n",
      "job       count    min threads    max threads\n",
      "------  -------  -------------  -------------\n",
      "fastqc        1              1              1\n",
      "total         1              1              1\n",
      "\n",
      "Select jobs to execute...\n",
      "\n",
      "[Tue Jun 14 13:57:01 2022]\n",
      "rule fastqc:\n",
      "    input: Data/SRR3099585_chr18.fastq.gz\n",
      "    output: FastQC/SRR3099585_chr18_fastqc.zip, FastQC/SRR3099585_chr18_fastqc.html\n",
      "    jobid: 0\n",
      "    reason: Missing output files: FastQC/SRR3099585_chr18_fastqc.zip, FastQC/SRR3099585_chr18_fastqc.html\n",
      "    resources: tmpdir=/tmp\n",
      "\n",
      "Started analysis of SRR3099585_chr18.fastq.gz\n",
      "Approx 5% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 10% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 15% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 20% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 25% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 30% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 35% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 40% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 45% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 50% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 55% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 60% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 65% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 70% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 75% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 80% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 85% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 90% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 95% complete for SRR3099585_chr18.fastq.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete for SRR3099585_chr18.fastq.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Tue Jun 14 13:57:05 2022]\n",
      "Finished job 0.\n",
      "1 of 1 steps (100%) done\n",
      "Complete log: .snakemake/log/2022-06-14T135701.418978.snakemake.log\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "snakemake --snakefile ex1_o1.smk --cores 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144cf3a8-1421-4fc7-8816-623c5883e674",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "**Observe result:** Look at the newly created `FastQC` directory: Snakemake create alone the needed directories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9342b477-3e5b-4a31-b655-27ff80660db8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Objective 2: One rule, 2 input files\n",
    "\n",
    "**Objective 2:** Add a second input RNAseq file to the rule.\n",
    "\n",
    "**Hint:**\n",
    "- second input file: `Data/SRR3099586_chr18.fastq.gz` \n",
    "- don‚Äôt forget to add the cognate output files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb697fb-2af4-468d-809d-3b6d38695a37",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Objective 2: Solution\n",
    "\n",
    "Code for `ex1_o2.smk`:\n",
    "```\n",
    "rule fastqc:\n",
    "  output:\n",
    "    \"FastQC/SRR3099585_chr18_fastqc.zip\", \n",
    "    \"FastQC/SRR3099585_chr18_fastqc.html\",\n",
    "    \"FastQC/SRR3099586_chr18_fastqc.zip\", \n",
    "    \"FastQC/SRR3099586_chr18_fastqc.html\"\n",
    "  input:\n",
    "    \"Data/SRR3099585_chr18.fastq.gz\",\n",
    "    \"Data/SRR3099586_chr18.fastq.gz\"\n",
    "  shell: \"fastqc --outdir FastQC/ {input}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2263019-d8be-4f3e-be80-becdb8b9d332",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building DAG of jobs...\n",
      "Using shell: /usr/bin/bash\n",
      "Provided cores: 1 (use --cores to define parallelism)\n",
      "Rules claiming more threads will be scaled down.\n",
      "Job stats:\n",
      "job       count    min threads    max threads\n",
      "------  -------  -------------  -------------\n",
      "fastqc        1              1              1\n",
      "total         1              1              1\n",
      "\n",
      "Select jobs to execute...\n",
      "\n",
      "[Tue Jun 14 14:03:32 2022]\n",
      "rule fastqc:\n",
      "    input: Data/SRR3099585_chr18.fastq.gz, Data/SRR3099586_chr18.fastq.gz\n",
      "    output: FastQC/SRR3099585_chr18_fastqc.zip, FastQC/SRR3099585_chr18_fastqc.html, FastQC/SRR3099586_chr18_fastqc.zip, FastQC/SRR3099586_chr18_fastqc.html\n",
      "    jobid: 0\n",
      "    reason: Missing output files: FastQC/SRR3099586_chr18_fastqc.html, FastQC/SRR3099586_chr18_fastqc.zip\n",
      "    resources: tmpdir=/tmp\n",
      "\n",
      "fastqc --outdir FastQC/ Data/SRR3099585_chr18.fastq.gz Data/SRR3099586_chr18.fastq.gz\n",
      "Started analysis of SRR3099585_chr18.fastq.gz\n",
      "Approx 5% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 10% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 15% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 20% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 25% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 30% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 35% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 40% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 45% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 50% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 55% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 60% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 65% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 70% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 75% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 80% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 85% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 90% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 95% complete for SRR3099585_chr18.fastq.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete for SRR3099585_chr18.fastq.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Started analysis of SRR3099586_chr18.fastq.gz\n",
      "Approx 5% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 10% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 15% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 20% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 25% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 30% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 35% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 40% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 45% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 50% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 55% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 60% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 65% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 70% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 75% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 80% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 85% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 90% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 95% complete for SRR3099586_chr18.fastq.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete for SRR3099586_chr18.fastq.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Tue Jun 14 14:03:40 2022]\n",
      "Finished job 0.\n",
      "1 of 1 steps (100%) done\n",
      "Complete log: .snakemake/log/2022-06-14T140331.819212.snakemake.log\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "snakemake -s ex1_o2.smk -c 1 -p # -s & -c : short forms of the -- snakefile & --cores options -p prints the command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0e672a-9043-4c0d-a6dd-535e74503f69",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**Observe results:**\n",
    "Snakemake rerun computation for the 1rst data file: its a new behavior from the v.7.8.0.<br>\n",
    "Before v.7.8.0, rerunning jobs relied purely on file modification times and the output files of the 1rst data file were not rerun. <br>\n",
    "After v.7.8.0, all provenance information is considered to define the jobs to rerun: parameter changes, code changes, software environment changes, and changes in the set of input files of a job (use the command line option `--rerun-triggers mtime` to use only modification time to determine whether a job shall be executed).\n",
    "\n",
    "Rerun without any changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e56292c-ed38-4594-bfa6-2d7c5c5bc1de",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building DAG of jobs...\n",
      "Nothing to be done (all requested files are present and up to date).\n",
      "Complete log: .snakemake/log/2022-06-14T140552.564187.snakemake.log\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "snakemake -s ex1_o2.smk -c 1 -p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1270316f-8b19-4f18-808d-76de92c1e2c0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Snakemake reply \"Nothing to be done\".\n",
    "\n",
    "Some solutions to rerun:\n",
    "- delete the `FastQC` directory and rerun the snakemake command\n",
    "- use the Snakemake `--forcerules` (`-R`) option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb26ad0-6570-41b3-99a5-232362f5895a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "rm -Rf FastQC\n",
    "snakemake -s ex1_o2.smk -c 1 -p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73fa881-319a-45fd-b07f-f0643b8a533b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "snakemake -s ex1_o2.smk -c 1 -p -R fastqc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17166942-760a-448e-b6f9-51558de77645",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Objective 3: Manage all the RNAseq files\n",
    "**Objective 3:** Add all the RNAseq files. \n",
    "\n",
    "Boring with writing all input and output file names? <br>\n",
    "Use the `expand()` function to manage all the input RNAseq files at once.\n",
    "\n",
    "**Hint:** \n",
    "- create a Python list at the begining of the snakefile and containing all the basename of the input files (don‚Äôt include the `.fastq.gz` suffix).\n",
    "- Python list format: `list_name = [\"item1\", \"item2\", ..., \"itemN\"]`\n",
    "- replace the filename lists of the input and output directives by the `expand()` function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255d683a-846b-4cf6-b68e-511874de5b66",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Objective 3: solution\n",
    "\n",
    "Code for `ex1_o3.smk`:\n",
    "```\n",
    "SAMPLES=[\"SRR3099585_chr18\",\"SRR3099586_chr18\",\"SRR3099587_chr18\"]\n",
    "\n",
    "rule fastqc:\n",
    "  output:\n",
    "    expand(\"FastQC/{sample}_fastqc.zip\", sample=SAMPLES),\n",
    "    expand(\"FastQC/{sample}_fastqc.html\", sample=SAMPLES)\n",
    "  input:\n",
    "    expand(\"data/{sample}.fastq.gz\", sample=SAMPLES)\n",
    "  shell: \"fastqc --outdir FastQC {input}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07c2c16f-19b8-4518-a465-e64d34742bf6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building DAG of jobs...\n",
      "MissingInputException in line 3 of /home/jovyan/tutoriel_smk/ex1_o3.smk:\n",
      "Missing input files for rule fastqc:\n",
      "    output: FastQC/SRR3099585_chr18_fastqc.zip, FastQC/SRR3099586_chr18_fastqc.zip, FastQC/SRR3099587_chr18_fastqc.zip, FastQC/SRR3099585_chr18_fastqc.html, FastQC/SRR3099586_chr18_fastqc.html, FastQC/SRR3099587_chr18_fastqc.html\n",
      "    affected files:\n",
      "        data/SRR3099585_chr18.fastq.gz\n",
      "        data/SRR3099587_chr18.fastq.gz\n",
      "        data/SRR3099586_chr18.fastq.gz\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'snakemake -c1 -s ex1_o3.smk --rerun-triggers mtime -p\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msnakemake -c1 -s ex1_o3.smk --rerun-triggers mtime -p\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2358\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2356\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2357\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2358\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/magics/script.py:153\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     line \u001b[38;5;241m=\u001b[39m script\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/magics/script.py:305\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'snakemake -c1 -s ex1_o3.smk --rerun-triggers mtime -p\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "snakemake -c1 -s ex1_o3.smk --rerun-triggers mtime -p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3364fad-6c27-4628-8778-8a6e39a46714",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**Observe the result:** The `--rerun-triggers mtime` option seems not to apply. Why?\n",
    "\n",
    "Look at the printed command line: one fastqc managing all imput files ; see also the _Job stats_ table (begining of the snakemake output):\n",
    "\n",
    "<img src=\"images/FAIR_smk_JobStats.png\" alt=\"Job stats table\" width=60%/>\n",
    "\n",
    "However, there are many input files but snakemake launched only one fastqc job.\n",
    "\n",
    "It is because the fastqc rule is defined with a list of files (the return format of the expand function) and not for one unique file and also because the fastqc tool accepts both a single file as well as a list of files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc97d0c6-9174-4753-b774-43540f052465",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Objective 4: Running n individual jobs\n",
    "\n",
    "**Objective 4:** add a rule containing the output files list and manage the fastqc rule to work with a single file\n",
    "\n",
    "**Hint:**\n",
    "- define a new rule, nammed _target_ with only an input directive based on the input of the fastqc rule\n",
    "- in the fastqc rule, replace the expand() function with a simple wildcard for the filename\n",
    "- suppress the `--rerun-triggers mtime` to see the effect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a23281-5ced-4a1f-8290-f8892dcac107",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Objective 4: Solution\n",
    "\n",
    "Code for ex1_o4.smk **change number**\n",
    "```\n",
    "SAMPLES = [\"SRR3099585_chr18\",\"SRR3099586_chr18\",\"SRR3099587_chr18\"]\n",
    "\n",
    "rule all:\n",
    "  input:\n",
    "    expand(\"FastQC/{sample}_fastqc.zip\", sample = SAMPLES),\n",
    "    expand(\"FastQC/{sample}_fastqc.html\", sample=SAMPLES)\n",
    "\n",
    "rule fastqc:\n",
    "  output:\n",
    "    \"FastQC/{sample}_fastqc.zip\",\n",
    "    \"FastQC/{sample}_fastqc.html\"\n",
    "  input:\n",
    "    \"Data/{sample}.fastq.gz\"\n",
    "  params: \"FastQC\"\n",
    "  shell: \"fastqc --outdir {params} {input}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed532f79-045f-4ebf-a4c1-dfdee628a0c7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building DAG of jobs...\n",
      "Using shell: /usr/bin/bash\n",
      "Provided cores: 1 (use --cores to define parallelism)\n",
      "Rules claiming more threads will be scaled down.\n",
      "Job stats:\n",
      "job       count    min threads    max threads\n",
      "------  -------  -------------  -------------\n",
      "all           1              1              1\n",
      "fastqc        3              1              1\n",
      "total         4              1              1\n",
      "\n",
      "Select jobs to execute...\n",
      "\n",
      "[Sun Jun 12 21:18:06 2022]\n",
      "rule fastqc:\n",
      "    input: Data/SRR3099585_chr18.fastq.gz\n",
      "    output: FastQC/SRR3099585_chr18_fastqc.zip, FastQC/SRR3099585_chr18_fastqc.html\n",
      "    jobid: 1\n",
      "    reason: Set of input files has changed since last execution; Code has changed since last execution; Params have changed since last execution\n",
      "    wildcards: sample=SRR3099585_chr18\n",
      "    resources: tmpdir=/tmp\n",
      "\n",
      "fastqc --outdir FastQC Data/SRR3099585_chr18.fastq.gz\n",
      "Started analysis of SRR3099585_chr18.fastq.gz\n",
      "Approx 5% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 10% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 15% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 20% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 25% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 30% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 35% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 40% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 45% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 50% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 55% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 60% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 65% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 70% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 75% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 80% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 85% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 90% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 95% complete for SRR3099585_chr18.fastq.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete for SRR3099585_chr18.fastq.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Sun Jun 12 21:18:14 2022]\n",
      "Finished job 1.\n",
      "1 of 4 steps (25%) done\n",
      "Select jobs to execute...\n",
      "\n",
      "[Sun Jun 12 21:18:14 2022]\n",
      "rule fastqc:\n",
      "    input: Data/SRR3099587_chr18.fastq.gz\n",
      "    output: FastQC/SRR3099587_chr18_fastqc.zip, FastQC/SRR3099587_chr18_fastqc.html\n",
      "    jobid: 3\n",
      "    reason: Set of input files has changed since last execution; Code has changed since last execution; Params have changed since last execution\n",
      "    wildcards: sample=SRR3099587_chr18\n",
      "    resources: tmpdir=/tmp\n",
      "\n",
      "fastqc --outdir FastQC Data/SRR3099587_chr18.fastq.gz\n",
      "Started analysis of SRR3099587_chr18.fastq.gz\n",
      "Approx 5% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 10% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 15% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 20% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 25% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 30% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 35% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 40% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 45% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 50% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 55% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 60% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 65% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 70% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 75% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 80% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 85% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 90% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 95% complete for SRR3099587_chr18.fastq.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete for SRR3099587_chr18.fastq.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Sun Jun 12 21:18:20 2022]\n",
      "Finished job 3.\n",
      "2 of 4 steps (50%) done\n",
      "Select jobs to execute...\n",
      "\n",
      "[Sun Jun 12 21:18:20 2022]\n",
      "rule fastqc:\n",
      "    input: Data/SRR3099586_chr18.fastq.gz\n",
      "    output: FastQC/SRR3099586_chr18_fastqc.zip, FastQC/SRR3099586_chr18_fastqc.html\n",
      "    jobid: 2\n",
      "    reason: Set of input files has changed since last execution; Code has changed since last execution; Params have changed since last execution\n",
      "    wildcards: sample=SRR3099586_chr18\n",
      "    resources: tmpdir=/tmp\n",
      "\n",
      "fastqc --outdir FastQC Data/SRR3099586_chr18.fastq.gz\n",
      "Started analysis of SRR3099586_chr18.fastq.gz\n",
      "Approx 5% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 10% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 15% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 20% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 25% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 30% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 35% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 40% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 45% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 50% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 55% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 60% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 65% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 70% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 75% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 80% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 85% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 90% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 95% complete for SRR3099586_chr18.fastq.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete for SRR3099586_chr18.fastq.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Sun Jun 12 21:18:27 2022]\n",
      "Finished job 2.\n",
      "3 of 4 steps (75%) done\n",
      "Select jobs to execute...\n",
      "\n",
      "[Sun Jun 12 21:18:27 2022]\n",
      "localrule all:\n",
      "    input: FastQC/SRR3099585_chr18_fastqc.zip, FastQC/SRR3099586_chr18_fastqc.zip, FastQC/SRR3099587_chr18_fastqc.zip, FastQC/SRR3099585_chr18_fastqc.html, FastQC/SRR3099586_chr18_fastqc.html, FastQC/SRR3099587_chr18_fastqc.html\n",
      "    jobid: 0\n",
      "    reason: Input files updated by another job: FastQC/SRR3099587_chr18_fastqc.html, FastQC/SRR3099587_chr18_fastqc.zip, FastQC/SRR3099585_chr18_fastqc.html, FastQC/SRR3099585_chr18_fastqc.zip, FastQC/SRR3099586_chr18_fastqc.html, FastQC/SRR3099586_chr18_fastqc.zip\n",
      "    resources: tmpdir=/tmp\n",
      "\n",
      "[Sun Jun 12 21:18:27 2022]\n",
      "Finished job 0.\n",
      "4 of 4 steps (100%) done\n",
      "Complete log: .snakemake/log/2022-06-12T211806.124892.snakemake.log\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "snakemake -c1 -s ex1_o3b.smk -p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df7ba85-dce9-40c7-8cfd-1125bd2a29c0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "**Observe the result:** the order of execution is not always the \"human\" order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef8cd1a-f5bf-4f5d-b1c9-5c4fbc8b980f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Objective 5: Add a second step\n",
    "**Objective 5:** with a second tool, it is a \"real\" analysis workflow!<br>\n",
    "The second tool multiqc will aggregate all the fastqc results.\n",
    "\n",
    "**Hint:**\n",
    "- multiqc inputs: the fastqc zip files\n",
    "- multiqc command: `multiqc *_fastqc.zip`\n",
    "- 2 outputs of multiqc: a file `multiqc_report.html` & a repository `multiqc_data` (to manage with `directory(\"multiqc_data\")`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9ec630-ffc1-4b29-a3bf-3fd63987a7d6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Objective 5: solution\n",
    "\n",
    "Code for `ex1_o6.smk`:\n",
    "```\n",
    "SAMPLES = [\"SRR3099585_chr18\",\"SRR3099586_chr18\",\"SRR3099587_chr18\"]\n",
    "\n",
    "rule all:\n",
    "  input:\n",
    "    expand(\"FastQC/{sample}_fastqc.html\", sample=SAMPLES),\n",
    "    \"multiqc_report.html\"\n",
    "\n",
    "rule multiqc:\n",
    "  output:\n",
    "    \"multiqc_report.html\",\n",
    "    directory(\"multiqc_data\")\n",
    "  input:\n",
    "    expand(\"FastQC/{sample}_fastqc.zip\", sample = SAMPLES)\n",
    "  shell: \"multiqc {input}\"\n",
    "\n",
    "rule fastqc:\n",
    "  output:\n",
    "    \"FastQC/{sample}_fastqc.zip\",\n",
    "    \"FastQC/{sample}_fastqc.html\"\n",
    "  input:\n",
    "    \"Data/{sample}.fastq.gz\"\n",
    "  params: \"FastQC\"\n",
    "  shell: \"fastqc --outdir {params} {input}\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "729015c6-3d93-45ef-a21a-c5f9677795b0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building DAG of jobs...\n",
      "Using shell: /usr/bin/bash\n",
      "Provided cores: 1 (use --cores to define parallelism)\n",
      "Rules claiming more threads will be scaled down.\n",
      "Job stats:\n",
      "job        count    min threads    max threads\n",
      "-------  -------  -------------  -------------\n",
      "all            1              1              1\n",
      "multiqc        1              1              1\n",
      "total          2              1              1\n",
      "\n",
      "Select jobs to execute...\n",
      "\n",
      "[Sun Jun 12 21:18:54 2022]\n",
      "rule multiqc:\n",
      "    input: FastQC/SRR3099585_chr18_fastqc.zip, FastQC/SRR3099586_chr18_fastqc.zip, FastQC/SRR3099587_chr18_fastqc.zip\n",
      "    output: multiqc_report.html, multiqc_data\n",
      "    jobid: 4\n",
      "    reason: Missing output files: multiqc_report.html\n",
      "    resources: tmpdir=/tmp\n",
      "\n",
      "multiqc FastQC/SRR3099585_chr18_fastqc.zip FastQC/SRR3099586_chr18_fastqc.zip FastQC/SRR3099587_chr18_fastqc.zip\n",
      "\n",
      "  /// MultiQC üîç | v1.12\n",
      "\n",
      "|           multiqc | Search path : /home/jovyan/tutoriel_smk/FastQC/SRR3099585_chr18_fastqc.zip\n",
      "|           multiqc | Search path : /home/jovyan/tutoriel_smk/FastQC/SRR3099586_chr18_fastqc.zip\n",
      "|           multiqc | Search path : /home/jovyan/tutoriel_smk/FastQC/SRR3099587_chr18_fastqc.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|         searching | ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 100% 3/3  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|            fastqc | Found 3 reports\n",
      "|           multiqc | Compressing plot data\n",
      "|           multiqc | Report      : multiqc_report.html\n",
      "|           multiqc | Data        : multiqc_data\n",
      "|           multiqc | MultiQC complete\n",
      "[Sun Jun 12 21:19:02 2022]\n",
      "Finished job 4.\n",
      "1 of 2 steps (50%) done\n",
      "Select jobs to execute...\n",
      "\n",
      "[Sun Jun 12 21:19:02 2022]\n",
      "localrule all:\n",
      "    input: FastQC/SRR3099585_chr18_fastqc.html, FastQC/SRR3099586_chr18_fastqc.html, FastQC/SRR3099587_chr18_fastqc.html, multiqc_report.html\n",
      "    jobid: 0\n",
      "    reason: Input files updated by another job: multiqc_report.html\n",
      "    resources: tmpdir=/tmp\n",
      "\n",
      "[Sun Jun 12 21:19:02 2022]\n",
      "Finished job 0.\n",
      "2 of 2 steps (100%) done\n",
      "Complete log: .snakemake/log/2022-06-12T211854.446695.snakemake.log\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "# rm -Rf multiqc_data\n",
    "snakemake -c1 -s ex1_o6.smk -p --rerun-triggers mtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9fb536-3402-457b-badb-9a31aa65f73b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Objective 6: Adding log file\n",
    "**Objective 6:** In Unix systems, the output of a command is usually sent to 2 separate\n",
    "streams: the expected output to Standard Out (stdout, or ‚Äù>‚Äù), and the error messages to Standard Error (stderr, or ‚Äù2>‚Äù). To integrate stderr and stdout into the same log, use ‚Äù&>‚Äù (use it with care because output files are often printed to stdout).\n",
    "\n",
    "**Hint:** \n",
    "- redirect the stdout and stderr streams of the fastqc and multiqc rules by adding a ‚Äùlog:‚Äù directive with two variables, out and err to separately redirect each streams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b623e762-bf3e-48da-a772-ebcb75f67e1e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Objective 6: Solution\n",
    "Code for ex1_o7.smk:\n",
    "```\n",
    "SAMPLES = [\"SRR3099585_chr18\",\"SRR3099586_chr18\",\"SRR3099587_chr18\"]\n",
    "\n",
    "rule all:\n",
    "  input:\n",
    "    expand(\"FastQC/{sample}_fastqc.html\", sample=SAMPLES),\n",
    "    \"multiqc_report.html\"\n",
    "\n",
    "rule multiqc:\n",
    "  output:\n",
    "    \"multiqc_report.html\"\n",
    "  input:\n",
    "    expand(\"FastQC/{sample}_fastqc.zip\", sample = SAMPLES)\n",
    "  log:\n",
    "    std=\"Logs/multiqc.std\",\n",
    "    err=\"Logs/multiqc.err\"\n",
    "  shell: \"multiqc {input} 1>{log.std} 2>{log.err}\" \n",
    "\n",
    "rule fastqc:\n",
    "  output:\n",
    "    \"FastQC/{sample}_fastqc.zip\",\n",
    "    \"FastQC/{sample}_fastqc.html\"\n",
    "  input:\n",
    "    \"Data/{sample}.fastq.gz\"\n",
    "  log:\n",
    "    std=\"Logs/{sample}_fastqc.std\",\n",
    "    err=\"Logs/{sample}_fastqc.err\"\n",
    "  shell: \"fastqc --outdir FastQC/ {input} 1>{log.std} 2>{log.err}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8225de45-7a25-4a52-9351-b5e698c21225",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building DAG of jobs...\n",
      "Using shell: /usr/bin/bash\n",
      "Provided cores: 1 (use --cores to define parallelism)\n",
      "Rules claiming more threads will be scaled down.\n",
      "Job stats:\n",
      "job        count    min threads    max threads\n",
      "-------  -------  -------------  -------------\n",
      "all            1              1              1\n",
      "fastqc         3              1              1\n",
      "multiqc        1              1              1\n",
      "total          5              1              1\n",
      "\n",
      "Select jobs to execute...\n",
      "\n",
      "[Sun Jun 12 21:20:01 2022]\n",
      "rule fastqc:\n",
      "    input: Data/SRR3099585_chr18.fastq.gz\n",
      "    output: FastQC/SRR3099585_chr18_fastqc.zip, FastQC/SRR3099585_chr18_fastqc.html\n",
      "    log: Logs/SRR3099585_chr18_fastqc.std, Logs/SRR3099585_chr18_fastqc.err\n",
      "    jobid: 1\n",
      "    reason: Code has changed since last execution; Params have changed since last execution\n",
      "    wildcards: sample=SRR3099585_chr18\n",
      "    resources: tmpdir=/tmp\n",
      "\n",
      "fastqc --outdir FastQC/ Data/SRR3099585_chr18.fastq.gz 1>Logs/SRR3099585_chr18_fastqc.std 2>Logs/SRR3099585_chr18_fastqc.err\n",
      "[Sun Jun 12 21:20:09 2022]\n",
      "Finished job 1.\n",
      "1 of 5 steps (20%) done\n",
      "Select jobs to execute...\n",
      "\n",
      "[Sun Jun 12 21:20:09 2022]\n",
      "rule fastqc:\n",
      "    input: Data/SRR3099587_chr18.fastq.gz\n",
      "    output: FastQC/SRR3099587_chr18_fastqc.zip, FastQC/SRR3099587_chr18_fastqc.html\n",
      "    log: Logs/SRR3099587_chr18_fastqc.std, Logs/SRR3099587_chr18_fastqc.err\n",
      "    jobid: 3\n",
      "    reason: Code has changed since last execution; Params have changed since last execution\n",
      "    wildcards: sample=SRR3099587_chr18\n",
      "    resources: tmpdir=/tmp\n",
      "\n",
      "fastqc --outdir FastQC/ Data/SRR3099587_chr18.fastq.gz 1>Logs/SRR3099587_chr18_fastqc.std 2>Logs/SRR3099587_chr18_fastqc.err\n",
      "[Sun Jun 12 21:20:15 2022]\n",
      "Finished job 3.\n",
      "2 of 5 steps (40%) done\n",
      "Select jobs to execute...\n",
      "\n",
      "[Sun Jun 12 21:20:15 2022]\n",
      "rule fastqc:\n",
      "    input: Data/SRR3099586_chr18.fastq.gz\n",
      "    output: FastQC/SRR3099586_chr18_fastqc.zip, FastQC/SRR3099586_chr18_fastqc.html\n",
      "    log: Logs/SRR3099586_chr18_fastqc.std, Logs/SRR3099586_chr18_fastqc.err\n",
      "    jobid: 2\n",
      "    reason: Code has changed since last execution; Params have changed since last execution\n",
      "    wildcards: sample=SRR3099586_chr18\n",
      "    resources: tmpdir=/tmp\n",
      "\n",
      "fastqc --outdir FastQC/ Data/SRR3099586_chr18.fastq.gz 1>Logs/SRR3099586_chr18_fastqc.std 2>Logs/SRR3099586_chr18_fastqc.err\n",
      "[Sun Jun 12 21:20:22 2022]\n",
      "Finished job 2.\n",
      "3 of 5 steps (60%) done\n",
      "Select jobs to execute...\n",
      "\n",
      "[Sun Jun 12 21:20:22 2022]\n",
      "rule multiqc:\n",
      "    input: FastQC/SRR3099585_chr18_fastqc.zip, FastQC/SRR3099586_chr18_fastqc.zip, FastQC/SRR3099587_chr18_fastqc.zip\n",
      "    output: multiqc_report.html, multiqc_data\n",
      "    log: Logs/multiqc.std, Logs/multiqc.err\n",
      "    jobid: 4\n",
      "    reason: Input files updated by another job: FastQC/SRR3099585_chr18_fastqc.zip, FastQC/SRR3099586_chr18_fastqc.zip, FastQC/SRR3099587_chr18_fastqc.zip\n",
      "    resources: tmpdir=/tmp\n",
      "\n",
      "multiqc FastQC/SRR3099585_chr18_fastqc.zip FastQC/SRR3099586_chr18_fastqc.zip FastQC/SRR3099587_chr18_fastqc.zip 1>Logs/multiqc.std 2>Logs/multiqc.err\n",
      "[Sun Jun 12 21:20:25 2022]\n",
      "Finished job 4.\n",
      "4 of 5 steps (80%) done\n",
      "Select jobs to execute...\n",
      "\n",
      "[Sun Jun 12 21:20:25 2022]\n",
      "localrule all:\n",
      "    input: FastQC/SRR3099585_chr18_fastqc.html, FastQC/SRR3099586_chr18_fastqc.html, FastQC/SRR3099587_chr18_fastqc.html, multiqc_report.html\n",
      "    jobid: 0\n",
      "    reason: Input files updated by another job: FastQC/SRR3099586_chr18_fastqc.html, multiqc_report.html, FastQC/SRR3099587_chr18_fastqc.html, FastQC/SRR3099585_chr18_fastqc.html\n",
      "    resources: tmpdir=/tmp\n",
      "\n",
      "[Sun Jun 12 21:20:25 2022]\n",
      "Finished job 0.\n",
      "5 of 5 steps (100%) done\n",
      "Complete log: .snakemake/log/2022-06-12T212001.252433.snakemake.log\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "# rm -Rf multiqc_data\n",
    "snakemake -c1 -s ex1_o7.smk -p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0b66e9-647a-432f-920b-98de7cb30330",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Snakemake point\n",
    "\n",
    "**So far, we‚Äôve seen:**\n",
    "- the rule and the workflow concepts, the snakefile\n",
    "- how rules are linked thank to input/output files and the first rule, the target rule\n",
    "- how to generalize the inputs of a rule using wildcards on filenames (and the expand function)\n",
    "- how to redirect stdout and stderr streams (log)\n",
    "\n",
    "**From now, we will seen some snakemake options:**\n",
    "- adding a configuration file\n",
    "- getting file names from the file system\n",
    "- to visualize the workflow diagram, use a dry-run option, etc\n",
    "- use a conda environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef54ff0c-c692-4d46-b4f1-b3af98116954",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "##¬†Objective 7: Use a configuration file\n",
    "**Why use a configuration file?**<br>\n",
    "To place all hard-coding values of the snakefile (paths to files, core numbers, parameter values, etc).\n",
    "\n",
    "**How to do it in Snakefile?**<br>\n",
    "Create a yml or json file and call the defined items with `config[\"myItem\"]`.\n",
    "And run with the `--configfile myConfig.yml` Snakemake option (an other solution is to add the directive `configfile: myConfig.yml` at the beginning of the snakefile)\n",
    "\n",
    "**Objective 7:** create `myConfig.yml` that specifies the the path of the data directory and replace the hard-coding values `\"Data/\"` in the snakefile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25493f8-b0d5-428a-8b3e-6a9910a1ff75",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Objective 7: Solution\n",
    "Code for `myConfig.yml`:\n",
    "```\n",
    "dataDir:\n",
    "  \"Data/\"\n",
    "```\n",
    "Copy `ex1_o7.smk` into `ex1_o7b.smk` and replace `Data/...` in inputs by a config call:\n",
    "```\n",
    "rule fastqc:\n",
    "  input:config[\"dataDir\"]+\"{sample}.fastq.gz\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3011f7eb-9eb7-4443-9631-c6192ebb4b4f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building DAG of jobs...\n",
      "Using shell: /usr/bin/bash\n",
      "Provided cores: 1 (use --cores to define parallelism)\n",
      "Rules claiming more threads will be scaled down.\n",
      "Job stats:\n",
      "job        count    min threads    max threads\n",
      "-------  -------  -------------  -------------\n",
      "all            1              1              1\n",
      "fastqc         3              1              1\n",
      "multiqc        1              1              1\n",
      "total          5              1              1\n",
      "\n",
      "Select jobs to execute...\n",
      "\n",
      "[Sun Jun 12 21:20:50 2022]\n",
      "rule fastqc:\n",
      "    input: Data/SRR3099585_chr18.fastq.gz\n",
      "    output: FastQC/SRR3099585_chr18_fastqc.zip, FastQC/SRR3099585_chr18_fastqc.html\n",
      "    log: Logs/SRR3099585_chr18_fastqc.std, Logs/SRR3099585_chr18_fastqc.err\n",
      "    jobid: 1\n",
      "    reason: Missing output files: FastQC/SRR3099585_chr18_fastqc.html, FastQC/SRR3099585_chr18_fastqc.zip\n",
      "    wildcards: sample=SRR3099585_chr18\n",
      "    resources: tmpdir=/tmp\n",
      "\n",
      "fastqc --outdir FastQC/ Data/SRR3099585_chr18.fastq.gz 1>Logs/SRR3099585_chr18_fastqc.std 2>Logs/SRR3099585_chr18_fastqc.err\n",
      "[Sun Jun 12 21:20:57 2022]\n",
      "Finished job 1.\n",
      "1 of 5 steps (20%) done\n",
      "Select jobs to execute...\n",
      "\n",
      "[Sun Jun 12 21:20:57 2022]\n",
      "rule fastqc:\n",
      "    input: Data/SRR3099587_chr18.fastq.gz\n",
      "    output: FastQC/SRR3099587_chr18_fastqc.zip, FastQC/SRR3099587_chr18_fastqc.html\n",
      "    log: Logs/SRR3099587_chr18_fastqc.std, Logs/SRR3099587_chr18_fastqc.err\n",
      "    jobid: 3\n",
      "    reason: Missing output files: FastQC/SRR3099587_chr18_fastqc.zip, FastQC/SRR3099587_chr18_fastqc.html\n",
      "    wildcards: sample=SRR3099587_chr18\n",
      "    resources: tmpdir=/tmp\n",
      "\n",
      "fastqc --outdir FastQC/ Data/SRR3099587_chr18.fastq.gz 1>Logs/SRR3099587_chr18_fastqc.std 2>Logs/SRR3099587_chr18_fastqc.err\n",
      "[Sun Jun 12 21:21:04 2022]\n",
      "Finished job 3.\n",
      "2 of 5 steps (40%) done\n",
      "Select jobs to execute...\n",
      "\n",
      "[Sun Jun 12 21:21:04 2022]\n",
      "rule fastqc:\n",
      "    input: Data/SRR3099586_chr18.fastq.gz\n",
      "    output: FastQC/SRR3099586_chr18_fastqc.zip, FastQC/SRR3099586_chr18_fastqc.html\n",
      "    log: Logs/SRR3099586_chr18_fastqc.std, Logs/SRR3099586_chr18_fastqc.err\n",
      "    jobid: 2\n",
      "    reason: Missing output files: FastQC/SRR3099586_chr18_fastqc.zip, FastQC/SRR3099586_chr18_fastqc.html\n",
      "    wildcards: sample=SRR3099586_chr18\n",
      "    resources: tmpdir=/tmp\n",
      "\n",
      "fastqc --outdir FastQC/ Data/SRR3099586_chr18.fastq.gz 1>Logs/SRR3099586_chr18_fastqc.std 2>Logs/SRR3099586_chr18_fastqc.err\n",
      "[Sun Jun 12 21:21:10 2022]\n",
      "Finished job 2.\n",
      "3 of 5 steps (60%) done\n",
      "Select jobs to execute...\n",
      "\n",
      "[Sun Jun 12 21:21:10 2022]\n",
      "rule multiqc:\n",
      "    input: FastQC/SRR3099585_chr18_fastqc.zip, FastQC/SRR3099586_chr18_fastqc.zip, FastQC/SRR3099587_chr18_fastqc.zip\n",
      "    output: multiqc_report.html, multiqc_data\n",
      "    log: Logs/multiqc.std, Logs/multiqc.err\n",
      "    jobid: 4\n",
      "    reason: Missing output files: multiqc_report.html; Input files updated by another job: FastQC/SRR3099586_chr18_fastqc.zip, FastQC/SRR3099585_chr18_fastqc.zip, FastQC/SRR3099587_chr18_fastqc.zip\n",
      "    resources: tmpdir=/tmp\n",
      "\n",
      "multiqc FastQC/SRR3099585_chr18_fastqc.zip FastQC/SRR3099586_chr18_fastqc.zip FastQC/SRR3099587_chr18_fastqc.zip 1>Logs/multiqc.std 2>Logs/multiqc.err\n",
      "[Sun Jun 12 21:21:13 2022]\n",
      "Finished job 4.\n",
      "4 of 5 steps (80%) done\n",
      "Select jobs to execute...\n",
      "\n",
      "[Sun Jun 12 21:21:13 2022]\n",
      "localrule all:\n",
      "    input: FastQC/SRR3099585_chr18_fastqc.html, FastQC/SRR3099586_chr18_fastqc.html, FastQC/SRR3099587_chr18_fastqc.html, multiqc_report.html\n",
      "    jobid: 0\n",
      "    reason: Input files updated by another job: multiqc_report.html, FastQC/SRR3099587_chr18_fastqc.html, FastQC/SRR3099585_chr18_fastqc.html, FastQC/SRR3099586_chr18_fastqc.html\n",
      "    resources: tmpdir=/tmp\n",
      "\n",
      "[Sun Jun 12 21:21:13 2022]\n",
      "Finished job 0.\n",
      "5 of 5 steps (100%) done\n",
      "Complete log: .snakemake/log/2022-06-12T212049.793914.snakemake.log\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "rm -Rf FastQC multiqc_data multiqc_report*\n",
    "snakemake -c1 -s ex1_o7b.smk -p --configfile myConfig.yml "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde9ef86-1e57-41a1-88b6-b999ffcb7b3c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Get input file names from the file system\n",
    "To deduce the identifiers (eg. IDs) of files in a directory, use the inbuilt `glob_wildcards` function, eg.:\n",
    "```\n",
    "IDs, = glob_wildcards(\"dirpath/{id}.txt\")\n",
    "```\n",
    "`glob_wildcards()` matches the given pattern against the files present in the system and thereby infers the values for all wildcards in the pattern (`{id}` here).\n",
    "\n",
    "**Hint:** Don‚Äôt forget the coma after the name (left hand side, IDs here)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c38e262-c4ac-4cf1-a9a5-4277a16904b3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Snakemake DAG visualization\n",
    "Snakemake uses `dot` tool (of the `graphviz` package) to create diagrams of the complete workflow (`--dag`) or the rules dependencies (`--rulegraph`):\n",
    "```\n",
    "snakemake --dag -s ex1_o7.smk | dot -Tpng > ex1_o7_dag.png\n",
    "snakemake --rulegraph -s ex1_o7.smk | dot -Tpng > ex1_o7_rule.png\n",
    "```\n",
    "\n",
    "<img src=\"images/ex1_o7_dag.png\" alt=\"DAG\" width=60%/> <img src=\"images/ex1_o7_rule.png\" alt=\"rules\" width=10%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce8f446-44b8-47d9-b89b-4f1a08e157e1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Conda environment\n",
    "\n",
    "Snakemake supports using explicit conda environments on a per-rule basis:<br>\n",
    "- add a conda: directive in the rule definition: `conda: myRuleEnvironment.yml`<br>\n",
    "- run Snakemake with the `--use-conda` option<br>\n",
    "\n",
    "The specified environment will be created and activated on the fly by Snakemake and the rule will then be run in the conda environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8810562-b371-42f2-9778-bc120d5b95bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Some other useful options\n",
    "\n",
    "- dry-run, do not execute anything, display what would be done: `-n --dryrun`\n",
    "- print the shell command: `-p --printshellcmds`\n",
    "- print the reason for each rule execution: `-r --reason`\n",
    "- print a summary and status of rule: `-D`\n",
    "- limit the number of jobs in parallel: `-j 1` (cores: `-c 1`)\n",
    "- automatically create HTML reports (`--report report.html`) containing runtime statistics, a visualization of the workflow topology, used software and data provenance information (need to add the `jinja2` package as a dependency)\n",
    "\n",
    "[all Snakemake options](https://snakemake.readthedocs.io/en/stable/executing/cli.html#all-option)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
